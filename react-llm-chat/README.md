# LLM Chat Interface - React Component

A reusable React component for creating chat interfaces with Large Language Models using the OpenRouter API. Features streaming responses, markdown rendering with MathJax support, and zero build step deployment.

## âœ¨ Features

- ğŸš€ **Zero Build Step** - Uses Babel standalone for JSX transformation
- ğŸ’¬ **Streaming Responses** - Real-time message streaming with fallback
- ğŸ“ **Markdown Support** - Full markdown rendering with MathJax for LaTeX
- ğŸ¨ **Customizable** - Extensive props API for customization
- â™¿ **Accessible** - Full ARIA support and keyboard navigation
- ğŸŒ™ **Dark Mode** - Built-in theming support
- ğŸ“± **Responsive** - Mobile-friendly design
- ğŸ”’ **Secure** - XSS protection and safe HTML rendering

## ğŸš€ Quick Start

### Basic Usage

```html
<!DOCTYPE html>
<html>
<head>
    <!-- React CDN -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    
    <!-- Dependencies -->
    <script src="https://cdn.jsdelivr.net/npm/markdown-it@13.0.1/dist/markdown-it.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- MathJax -->
    <script>
        window.MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\\\(', '\\\\)']], displayMath: [['$$', '$$'], ['\\\\[', '\\\\]']] }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <!-- Component CSS -->
    <link href="src/styles/chat.css" rel="stylesheet">
</head>
<body>
    <div id="chat-root"></div>
    
    <script type="text/babel" data-type="module">
        import LLMChatInterface from './src/LLMChatInterface.jsx';
        
        const App = () => (
            <LLMChatInterface apiKey="your-openrouter-api-key" />
        );
        
        const root = ReactDOM.createRoot(document.getElementById('chat-root'));
        root.render(<App />);
    </script>
</body>
</html>
```

### Customized Usage

```jsx
<LLMChatInterface
    apiKey="your-api-key"
    defaultModel="anthropic/claude-3-sonnet"
    systemPrompt="You are a helpful coding assistant."
    height="500px"
    theme="dark"
    showModelSelector={false}
    onMessage={(message, response) => console.log('Chat:', message, response)}
    onError={(error) => console.error('Error:', error)}
/>
```

## ğŸ“– Props API

| Prop | Type | Default | Description |
|------|------|---------|-------------|
| `apiKey` | `string` | **required** | OpenRouter API key |
| `defaultModel` | `string` | `"openai/gpt-4o-mini"` | Initial model selection |
| `systemPrompt` | `string` | Default assistant prompt | Custom system prompt |
| `className` | `string` | `""` | Additional CSS classes |
| `height` | `string` | `"600px"` | Component height |
| `showHeader` | `boolean` | `true` | Show/hide header controls |
| `showModelSelector` | `boolean` | `true` | Show/hide model dropdown |
| `showClearButton` | `boolean` | `true` | Show/hide clear button |
| `showDisplayModeToggle` | `boolean` | `true` | Show/hide display mode toggle |
| `onMessage` | `function` | `null` | Callback for message events |
| `onError` | `function` | `null` | Callback for errors |
| `customModels` | `array` | `null` | Override default model list |
| `theme` | `string` | `"light"` | UI theme (`"light"` or `"dark"`) |

## ğŸ¨ Styling

The component uses scoped CSS classes prefixed with `llm-chat-` to avoid conflicts. You can customize the appearance by overriding CSS custom properties:

```css
.llm-chat-container {
    --llm-chat-primary: #your-color;
    --llm-chat-background: #your-background;
    /* ... other variables */
}
```

## ğŸ”§ Development

```bash
# Start development server
python -m http.server 8080

# Open in browser
http://localhost:8080
```

## ğŸ“ Project Structure

```
react-llm-chat/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ LLMChatInterface.jsx      # Main component
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useChatEngine.js      # Chat logic hook
â”‚   â”‚   â”œâ”€â”€ useMarkdownRenderer.js # Markdown rendering
â”‚   â”‚   â””â”€â”€ useModelManager.js    # Model management
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatHeader.jsx        # Header controls
â”‚   â”‚   â”œâ”€â”€ MessageList.jsx       # Message display
â”‚   â”‚   â”œâ”€â”€ MessageInput.jsx      # Input area
â”‚   â”‚   â””â”€â”€ ErrorDisplay.jsx      # Error handling
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ apiClient.js          # OpenRouter API client
â”‚   â”‚   â”œâ”€â”€ mathProcessor.js      # Math rendering utilities
â”‚   â”‚   â””â”€â”€ constants.js          # App constants
â”‚   â””â”€â”€ styles/
â”‚       â””â”€â”€ chat.css              # Component styles
â”œâ”€â”€ index.html                    # Basic demo
â”œâ”€â”€ demo.html                     # Usage examples
â””â”€â”€ README.md                     # This file
```

## ğŸ§ª Examples

See `demo.html` for comprehensive usage examples including:

- Basic chat interface
- Customized styling and behavior
- Dark theme implementation
- Minimal interface without controls

## ğŸ”‘ API Key

Get your OpenRouter API key from [OpenRouter.ai](https://openrouter.ai). The component supports all models available through OpenRouter.

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ†˜ Support

- ğŸ“š [Documentation](https://github.com/your-repo/llm-chat-interface/docs)
- ğŸ› [Issue Tracker](https://github.com/your-repo/llm-chat-interface/issues)
- ğŸ’¬ [Discussions](https://github.com/your-repo/llm-chat-interface/discussions)

---

Built with â¤ï¸ for the AI community